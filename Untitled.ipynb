{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7001e1-7515-49a0-bd89-8b535e0e0314",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0da4522153e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m aa_encoding = {\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pandas.core.frame import DataFrame\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "aa_encoding = {\n",
    "    \"ala\": 0,\n",
    "    \"arg\": 1,\n",
    "    \"asn\": 2,\n",
    "    \"asp\": 3,\n",
    "    \"cys\": 4,\n",
    "    \"gln\": 5,\n",
    "    \"glu\": 6,\n",
    "    \"gly\": 7,\n",
    "    \"his\": 8,\n",
    "    \"ile\": 9,\n",
    "    \"leu\": 10,\n",
    "    \"lys\": 11,\n",
    "    \"met\": 12,\n",
    "    \"phe\": 13,\n",
    "    \"pro\": 14,\n",
    "    \"ser\": 15,\n",
    "    \"thr\": 16,\n",
    "    \"trp\": 17,\n",
    "    \"tyr\": 18,\n",
    "    \"val\": 19,\n",
    "}\n",
    "\n",
    "edge_type_encoding = {\"cnt\": 0, \"combi\": 1, \"hbond\": 2, \"pept\": 3, \"ovl\": 4}\n",
    "\n",
    "\n",
    "def onehot_encode(position: int, count: Optional[int] = 20):\n",
    "    \"\"\"One-hot encode position\n",
    "    Args:\n",
    "        position (int): Which entry to set to 1\n",
    "        count (Optional[int], optional): Max number of entries. Defaults to 20.\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    t = [0] * count\n",
    "    t[position] = 1\n",
    "    return t\n",
    "\n",
    "\n",
    "class ProteinEncoder:\n",
    "    def __init__(self, config: dict):\n",
    "        self.features = config[\"node_features\"]\n",
    "        self.edge_features = config[\"edge_features\"]\n",
    "\n",
    "    def encode_residue(self, residue: str) -> np.array:\n",
    "        \"\"\"Fully encode residue - one-hot and features\n",
    "\n",
    "        Args:\n",
    "            residue (str): One-letter residue name\n",
    "\n",
    "        Returns:\n",
    "            np.array: Concatenated features and one-hot encoding of residue name\n",
    "        \"\"\"\n",
    "        if residue.lower() not in aa_encoding:\n",
    "            return None\n",
    "        elif self.features == \"label\":\n",
    "            return aa_encoding[residue.lower()]\n",
    "        elif self.features == \"onehot\":\n",
    "            return onehot_encode(aa_encoding[residue.lower()])\n",
    "        else:\n",
    "            raise ValueError(\"Unknown features type!\")\n",
    "\n",
    "    def parse_sif(self, filename: str) -> Tuple[DataFrame, DataFrame]:\n",
    "        \"\"\"Parse a single sif file\n",
    "\n",
    "        Args:\n",
    "            filename (str): SIF file location\n",
    "\n",
    "        Returns:\n",
    "            Tuple[DataFrame, DataFrame]: nodes, edges DataFrames\n",
    "        \"\"\"\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                splitline = line.split()\n",
    "                if len(splitline) != 3:\n",
    "                    continue\n",
    "                node1, edgetype, node2 = splitline\n",
    "                node1split = node1.split(\":\")\n",
    "                node2split = node2.split(\":\")\n",
    "                if len(node1split) != 4:\n",
    "                    continue\n",
    "                if len(node2split) != 4:\n",
    "                    continue\n",
    "                chain1, resn1, x1, resaa1 = node1split\n",
    "                chain2, resn2, x2, resaa2 = node2split\n",
    "                if x1 != \"_\" or x2 != \"_\":\n",
    "                    continue\n",
    "                if resaa1.lower() not in aa_encoding or resaa2.lower() not in aa_encoding:\n",
    "                    continue\n",
    "                resn1 = int(resn1)\n",
    "                resn2 = int(resn2)\n",
    "                if resn1 == resn2:\n",
    "                    continue\n",
    "                edgesplit = edgetype.split(\":\")\n",
    "                if len(edgesplit) != 2:\n",
    "                    continue\n",
    "                node1 = {\"chain\": chain1, \"resn\": resn1, \"resaa\": resaa1}\n",
    "                node2 = {\"chain\": chain2, \"resn\": resn2, \"resaa\": resaa2}\n",
    "                edgetype, _ = edgesplit\n",
    "                edge = {\n",
    "                    \"resn1\": resn1,\n",
    "                    \"resn2\": resn2,\n",
    "                    \"type\": edgetype,\n",
    "                }\n",
    "                nodes.append(node1)\n",
    "                nodes.append(node2)\n",
    "                edges.append(edge)\n",
    "        nodes = pd.DataFrame(nodes).drop_duplicates()\n",
    "        nodes = nodes.sort_values(\"resn\").reset_index(drop=True).reset_index().set_index(\"resn\")\n",
    "        edges = pd.DataFrame(edges).drop_duplicates()\n",
    "        node_idx = nodes[\"index\"].to_dict()\n",
    "        edges[\"node1\"] = edges[\"resn1\"].apply(lambda x: node_idx[x])\n",
    "        edges[\"node2\"] = edges[\"resn2\"].apply(lambda x: node_idx[x])\n",
    "        return nodes, edges\n",
    "\n",
    "    def encode_nodes(self, nodes: pd.DataFrame) -> torch.Tensor:\n",
    "        \"\"\"Given dataframe of nodes create node features\n",
    "\n",
    "        Args:\n",
    "            nodes (pd.DataFrame): nodes dataframe from parse_sif\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of node features [n_nodes, *]\n",
    "        \"\"\"\n",
    "        nodes.drop_duplicates(inplace=True)\n",
    "        node_attr = [self.encode_residue(x) for x in nodes[\"resaa\"]]\n",
    "        node_attr = [x for x in node_attr if x is not None]\n",
    "        node_attr = np.asarray(node_attr)\n",
    "        if self.features == \"label\":\n",
    "            node_attr = torch.tensor(node_attr, dtype=torch.long)\n",
    "        else:\n",
    "            node_attr = torch.tensor(node_attr, dtype=torch.float32)\n",
    "        return node_attr\n",
    "\n",
    "    def encode_edges(self, edges: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Given dataframe of edges, create edge index and edge attributes\n",
    "\n",
    "        Args:\n",
    "            edges (pd.DataFrame): edges dataframe from parse_sif\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: edge index [2,n_edges], edge attributes [n_edges, *]\n",
    "        \"\"\"\n",
    "        edges.drop_duplicates(inplace=True)\n",
    "        edge_index = edges[[\"node1\", \"node2\"]].astype(int).values\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        edge_index = edge_index.t().contiguous()\n",
    "        if self.edge_features == \"none\":\n",
    "            return edge_index, None\n",
    "        edge_features = edges[\"type\"].apply(lambda x: edge_type_encoding[x])\n",
    "        if self.edge_features == \"label\":\n",
    "            edge_features = torch.tensor(edge_features, dtype=torch.long)\n",
    "            edge_index, edge_features = to_undirected(edge_index, edge_features)\n",
    "            return edge_index, edge_features\n",
    "        elif self.edge_features == \"onehot\":\n",
    "            edge_features = edge_features.apply(onehot_encode, count=len(edge_type_encoding))\n",
    "            edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "            edge_index, edge_features = to_undirected(edge_index, edge_features)\n",
    "            return edge_index, edge_features\n",
    "\n",
    "    def __call__(self, protein_sif: str) -> dict:\n",
    "        \"\"\"Fully process the protein\n",
    "\n",
    "        Args:\n",
    "            protein_sif (str): File location for sif file\n",
    "\n",
    "        Returns:\n",
    "            dict: standard format with x for node features, edge_index for edges etc\n",
    "        \"\"\"\n",
    "        nodes, edges = self.parse_sif(protein_sif)\n",
    "        node_attr = self.encode_nodes(nodes)\n",
    "        edge_index, edge_attr = self.encode_edges(edges)\n",
    "        return dict(x=node_attr, edge_index=edge_index, edge_attr=edge_attr, index_mapping=nodes[\"index\"].to_dict())\n",
    "\n",
    "\n",
    "def extract_name(protein_sif: str) -> str:\n",
    "    \"\"\"Extract the protein name from the sif filename\"\"\"\n",
    "    return protein_sif.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    proteins = pd.Series(list(snakemake.input.rins), name=\"sif\")\n",
    "    proteins = pd.DataFrame(proteins)\n",
    "    proteins[\"ID\"] = proteins[\"sif\"].apply(extract_name)\n",
    "    proteins.set_index(\"ID\", inplace=True)\n",
    "    prot_encoder = ProteinEncoder(snakemake.config)\n",
    "    proteins[\"data\"] = proteins[\"sif\"].apply(prot_encoder)\n",
    "    with open(snakemake.output.protein_pickle, \"wb\") as file:\n",
    "        pickle.dump(proteins, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccf4bf-fe31-4047-a246-a75846b42444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
